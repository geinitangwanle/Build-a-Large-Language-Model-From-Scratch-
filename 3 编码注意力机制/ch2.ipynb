{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e578dd",
   "metadata": {},
   "source": [
    "# 从零手搓GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de979821",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, #词汇表大小\n",
    "    \"context_length\": 1024, #上下文长度\n",
    "    \"emb_dim\": 768, #词嵌入维度\n",
    "    \"n_layers\": 12, #层数\n",
    "    \"n_heads\": 12, #注意力头数\n",
    "    \"drop_rate\": 0.1, #dropout率\n",
    "    \"qkv_bias\": False #是否使用偏置\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c793531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d19e4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "737b2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "batch = torch.tensor([[6109,3626,6100,345],\n",
    "                [6109,1110,6622,257]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c269636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bb98c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "layer = nn.Sequential(\n",
    "    nn.Linear(5,6),\n",
    "    nn.ReLU()\n",
    ")\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d55fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>) tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1,keepdim=True)\n",
    "var = out.var(dim=-1,keepdim=True)\n",
    "print(mean,var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d30eb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>) tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1,keepdim=True)\n",
    "var = out_norm.var(dim=-1,keepdim=True)\n",
    "print(out_norm)\n",
    "print(mean,var)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ec612fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # 防止方差为0\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "610b32bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>) tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1,keepdim=True)\n",
    "var = out_ln.var(dim=-1,keepdim=True,unbiased=False)\n",
    "print(mean,var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7efa8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a2e548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-5,5,100)\n",
    "y_gelu = gelu(x)\n",
    "y_relu = relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate([(y_gelu, \"GELU\"), (y_relu, \"ReLU\")]):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(label)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3c1fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a52c04a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43264352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]),GELU()),\n",
    "                                    nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),GELU()),\n",
    "                                    nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),GELU()),\n",
    "                                    nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),GELU()),\n",
    "                                    nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),GELU()),\n",
    "                                    ])\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        \n",
    "        return x\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75d44eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fe441ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9df3dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2a03400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0014432291500270367\n",
      "layers.1.0.weight has gradient mean of 0.004846951924264431\n",
      "layers.2.0.weight has gradient mean of 0.004138893447816372\n",
      "layers.3.0.weight has gradient mean of 0.005915115587413311\n",
      "layers.4.0.weight has gradient mean of 0.032659437507390976\n"
     ]
    }
   ],
   "source": [
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0219d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) #构造一个线性层，将多头注意力的输出投影到与输入相同的维度\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape #批次，token数量，输入向量维度\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1505b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73b01ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "531809d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        device = in_idx.device\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16eb4376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2153, -0.2156, -0.5981,  ..., -1.3757,  0.0148, -0.4112],\n",
      "         [-0.3205,  0.1482,  0.1342,  ...,  0.0041,  1.5363,  0.6325],\n",
      "         [ 0.8451,  1.5721, -0.3732,  ...,  1.2597, -0.5085,  0.5366],\n",
      "         [ 0.1805,  1.7914, -0.7846,  ...,  1.5559,  0.7674, -0.9654]],\n",
      "\n",
      "        [[-1.1209,  0.1907, -0.4728,  ..., -1.6933,  0.4509, -0.8067],\n",
      "         [-0.2541,  0.6058, -0.5057,  ..., -0.0369,  0.4535,  1.1430],\n",
      "         [ 1.1658,  1.5483, -0.3557,  ..., -0.6638, -0.0425,  0.5066],\n",
      "         [-0.5266, -0.7271, -0.2477,  ...,  1.9617, -0.0376, -0.4280]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "gpt_model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input:\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f45b6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 163009536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in gpt_model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93f20187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output head layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output head layer shape:\", model.out_head.weight.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "624fea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of GPT-2: 124412160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total parameters of GPT-2: {total_params_gpt2}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0153a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total size: {total_size_mb:.2f} MB\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "603ceb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim = -1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faa808b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tensor = torch.tensor([[15496,11,314,716]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf7b4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 12170, 44251, 25952, 49216, 30322,  6868]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee903c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eafed12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text: Hello, I am drone Omni SSLmyra muc native\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5aedc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, #词汇表大小\n",
    "    \"context_length\": 256, #上下文长度\n",
    "    \"emb_dim\": 768, #词嵌入维度\n",
    "    \"n_layers\": 12, #层数\n",
    "    \"n_heads\": 12, #注意力头数\n",
    "    \"drop_rate\": 0.1, #dropout率\n",
    "    \"qkv_bias\": False #是否使用偏置\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1522c6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "243ac4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(model=model, idx = text_to_token_ids(start_context, tokenizer),\n",
    "                                                max_new_tokens=10, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "\n",
    "print(\"Output text:\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "773011b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],[40, 1107, 588]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ca617ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345],[1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03ff434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a9e20520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim = -1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de2b971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标批次 1:  effort moves you\n",
      "目标批次 2:  really like chocolate\n",
      "输出批次 1:  Armed heNetflix\n",
      "输出批次 2:  pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "print(f\"目标批次 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"目标批次 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"输出批次 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "print(f\"输出批次 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2cc73ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "文本 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2],targets[text_idx]]\n",
    "print(\"文本 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2],targets[text_idx]]\n",
    "print(\"文本 2:\", target_probas_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3729eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6f090b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均对数概率: -10.793963432312012\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(f\"平均对数概率: {avg_log_probas}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e83fa5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负平均对数概率: 10.793963432312012\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(f\"负平均对数概率: {neg_avg_log_probas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95d06e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits 形状： torch.Size([2, 3, 50257])\n",
      "目标 形状 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits 形状：\", logits.shape)\n",
    "print(\"目标 形状\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e260cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_flat 形状： torch.Size([6, 50257])\n",
      "targets_flat 形状： torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"logits_flat 形状：\", logits_flat.shape)\n",
    "print(\"targets_flat 形状：\", targets_flat.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ac9469d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失：10.793964385986328\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(f\"损失：{loss}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "32f85f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度: 48725.8203125\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(f\"困惑度: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "94fb7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/tangren/Documents/Build-a-Large-Language-Model-From-Scratch-/the-verdict.txt\"\n",
    "with open(file_path, \"r\",encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38760926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字符总数: 20479\n",
      "token总数: 5145\n"
     ]
    }
   ],
   "source": [
    "total_charcter = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"字符总数: {total_charcter}\")\n",
    "print(f\"token总数: {total_tokens}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9329b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 滑动窗口数据采样\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "\n",
    "            \n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a693a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字符数: 20479\n",
      "训练集字符数: 18431\n",
      "验证集字符数: 2048\n"
     ]
    }
   ],
   "source": [
    "# 读取文本数据\n",
    "with open(\"/Users/tangren/Documents/Build-a-Large-Language-Model-From-Scratch-/the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# 按90%/10%的比例划分训练集和验证集\n",
    "total_characters = len(text_data)\n",
    "split_idx = int(0.90 * total_characters)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "print(f\"总字符数: {total_characters}\")\n",
    "print(f\"训练集字符数: {len(train_data)}\")\n",
    "print(f\"验证集字符数: {len(val_data)}\")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], \n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05ae2d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "80d9f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b658b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bc6c895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 10.98758316040039\n",
      "验证损失: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = clac_loss_loader(train_loader, model, device)\n",
    "    val_loss = clac_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"训练损失: {train_loss}\")\n",
    "print(f\"验证损失: {val_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07be3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = clac_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = clac_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded =  text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(f\"生成样本: {decoded_text}\")\n",
    "    model.train()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d1d7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(token_seen)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Step {global_step}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "                \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed4c93d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Step 0, Train Loss: 9.8168, Val Loss: 9.9238\n",
      "Epoch 1/10, Step 5, Train Loss: 8.0657, Val Loss: 8.3325\n",
      "生成样本: Every effort moves you,,,,,,,,,,,,.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10, Step 10, Train Loss: 6.6193, Val Loss: 7.0424\n",
      "Epoch 2/10, Step 15, Train Loss: 6.0457, Val Loss: 6.5960\n",
      "生成样本: Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Epoch 3/10, Step 20, Train Loss: 5.5236, Val Loss: 6.5077\n",
      "Epoch 3/10, Step 25, Train Loss: 5.3691, Val Loss: 6.3776\n",
      "生成样本: Every effort moves you, and to the of the of the picture. Gis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10, Step 30, Train Loss: 4.8300, Val Loss: 6.2628\n",
      "Epoch 4/10, Step 35, Train Loss: 4.5863, Val Loss: 6.2846\n",
      "生成样本: Every effort moves you of the\n",
      "\"I the picture.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Epoch 5/10, Step 40, Train Loss: 3.8794, Val Loss: 6.1303\n",
      "生成样本: Every effort moves you know he had been his pictures, and I felt it's by his last word.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and he had been the end, and he had been\n",
      "Epoch 6/10, Step 45, Train Loss: 3.5297, Val Loss: 6.1832\n",
      "Epoch 6/10, Step 50, Train Loss: 2.9600, Val Loss: 6.1233\n",
      "生成样本: Every effort moves you know it was his pictures--I glanced after him, I had the last word.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and I was his pictures--I looked.\n",
      "\n",
      "\n",
      "\"I looked.\n",
      "\"I looked.\n",
      "\n",
      "Epoch 7/10, Step 55, Train Loss: 2.8323, Val Loss: 6.1503\n",
      "Epoch 7/10, Step 60, Train Loss: 2.1036, Val Loss: 6.1335\n",
      "生成样本: Every effort moves you know the picture to me--I glanced after him, and Mrs.\n",
      "\n",
      "\"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Epoch 8/10, Step 65, Train Loss: 1.6912, Val Loss: 6.1862\n",
      "Epoch 8/10, Step 70, Train Loss: 1.3908, Val Loss: 6.2295\n",
      "生成样本: Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Epoch 9/10, Step 75, Train Loss: 1.0586, Val Loss: 6.2509\n",
      "Epoch 9/10, Step 80, Train Loss: 0.7999, Val Loss: 6.2780\n",
      "生成样本: Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"\n",
      "\n",
      "He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Epoch 10/10, Step 85, Train Loss: 0.5689, Val Loss: 6.3726\n",
      "生成样本: Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs = num_epochs,\n",
    "    eval_freq = 5,\n",
    "    eval_iter = 5,\n",
    "    start_context = \"Every effort moves you\",\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "48a4e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"train loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, label=\"val loss\")\n",
    "    ax1.set_xlabel(\"epochs\")\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax1.legend(loc = \"upper left\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0.5)\n",
    "    ax2.set_xlabel(\"tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc8b252b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_seen = list(range(len(train_losses)))\n",
    "plot_losses(epochs_seen, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f759550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "978d98f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成样本: Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(f\"生成样本: {decoded_text}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5be4ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8fdcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "50368ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "304de736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3546e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f68844dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits= logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b1c62704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/c200w_zx7rgfj5q934zb6vgm0000gn/T/ipykernel_14100/43499487.py:11: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(vocab.keys(),rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEaklEQVR4nO3de1QV1d8/8PcBucpN4iaIgpcSijtqeEPLAjXUfDRTzEvob5mZBqFfLQSBAL+pRBaGqZilJmVkFmohiYiXvCBoaRAgQsqtTAhRQM78/vBxno6Acp/D4f1aa9Zi9uyZ+ZzTWX3ce/bsLRMEQQAREREpJTWpAyAiIqKmMVETEREpMSZqIiIiJcZETUREpMSYqImIiJQYEzUREZESY6ImIiJSYkzURERESqyH1AF0NrlcjuvXr0NfXx8ymUzqcIiIqBsSBAH//PMPLC0toab28DZzt0vU169fh7W1tdRhEBERoaioCH369HlonW6XqPX19QHc+3IMDAwkjoaIiLqjyspKWFtbiznpYbpdor7f3W1gYMBETUREkmrOI1hJB5OlpaXBx8cHlpaWkMlk2Ldv3yPPSU1NhaurK7S0tDBw4EB8+umnHR4nERGRVCRN1Ldu3YKTkxNiY2ObVf/KlSuYOHEixo4di8zMTLz55ptYsGABfvjhhw6OlIiISBqSdn2PHz8e48ePb3b9uLg42NraYsOGDQAAOzs7pKen4/3334eXl1dHhUlERCSZLvWM+uTJkxg3bpxCmZeXF958880mz6mpqUFNTY24X1lZ2VHhEVE7kcvlqK2tlToMolbT0NCAurp6u1yrSyXqkpISmJubK5SZm5ujsrISt2/fho6OToNzoqKiEBoa2lkhElEb1dbW4sqVK5DL5VKHQtQmRkZGsLCwaPOcHV0qUbfGqlWrEBAQIO7fHxJPRMpHEAQUFxdDXV0d1tbWj5wIgkgZCYKA6upqlJWVAQB69+7dput1qURtYWGB0tJShbLS0lIYGBg02poGAC0tLWhpaXVGeETNt8bwIccqOi8OJXP37l1UV1fD0tISurq6UodD1Gr3c1JZWRnMzMza1A3epf656uHhgZSUFIWy5ORkeHh4SBQREbWn+vp6AICmpqbEkRC13f1/bNbV1bXpOpIm6qqqKmRmZiIzMxPAvdevMjMzUVhYCOBet/WcOXPE+osWLUJ+fj5WrFiB3377DZs2bcKXX34Jf39/KcInog7CefhJFbTX71jSRH327Fm4uLjAxcUFABAQEAAXFxcEBwcDAIqLi8WkDQC2trZISkpCcnIynJycsGHDBmzdupWvZhERkcqSNFGPGTMGgiA02O7PNvbpp58iNTW1wTnnz59HTU0N8vLyMG/evE6Pm4joPplM9tBtzZo1UofY7mxsbBATEyN1GG2ydOlSuLm5QUtLC87OzlKH81BdajAZEXVPNiuTOvV+BWsnNrtucXGx+HdCQgKCg4ORnZ0tlunp6bVrbB1FEATU19ejR4/OSwu1tbWSjkd49dVX8fPPP+PChQuSxdAcXWowGRGRsrGwsBA3Q0NDyGQyhbI9e/bAzs4O2traGDx4MDZt2iSeW1BQAJlMhi+//BKjRo2Cjo4OhgwZgpycHJw5cwbu7u7Q09PD+PHjUV5eLp43b948TJkyBaGhoTA1NYWBgQEWLVqkMEmMXC5HVFQUbG1toaOjAycnJ+zdu1c8npqaCplMhoMHD4oty/T0dOTl5WHy5MkwNzeHnp4ehgwZgsOHD4vnjRkzBlevXoW/v7/YawAAa9asadAyjYmJgY2NTYO4IyIiYGlpiSeeeALAvdUMX3rpJRgZGcHY2BiTJ09GQUFBe/znadLGjRvx+uuvo3///h16n/bARE1E1EF27dqF4OBgRERE4PLly4iMjMTq1auxY8cOhXohISEICgpCRkYGevTogVmzZmHFihX44IMPcOzYMeTm5opjd+5LSUnB5cuXkZqaii+++AKJiYkKkztFRUXhs88+Q1xcHH799Vf4+/tj9uzZOHr0qMJ1Vq5cibVr1+Ly5ctwdHREVVUVJkyYgJSUFJw/fx7e3t7w8fERxwslJiaiT58+CAsLQ3FxsUKPQnOkpKQgOzsbycnJ+P7771FXVwcvLy/o6+vj2LFjOH78OPT09ODt7f3Q2en09PQeui1atKhFcSkzdn0TEXWQkJAQbNiwAVOnTgVwb0DspUuXsHnzZsydO1esFxgYKA6KXbZsGWbOnImUlBSMGDECAODn59dgpUBNTU3Ex8dDV1cXTz75JMLCwrB8+XKEh4ejrq4OkZGROHz4sPj6av/+/ZGeno7NmzfD09NTvE5YWBiee+45cd/Y2BhOTk7ifnh4OL755hvs378fS5YsgbGxMdTV1aGvrw8LC4sWfyc9e/bE1q1bxS7vnTt3Qi6XY+vWrWLrfPv27TAyMkJqaiqef/75Rq9z/22hpqjSMsZM1EREHeDWrVvIy8uDn58fFi5cKJbfvXsXhoaKE944OjqKf9+fJtnBwUGh7P4sV/c5OTkpTArj4eGBqqoqFBUVoaqqCtXV1QoJGLj3TPj+Wzb3ubu7K+xXVVVhzZo1SEpKQnFxMe7evYvbt28rvIHTFg4ODgrPpbOyspCbmwt9fX2Fenfu3EFeXl6T1xk4cGC7xNMVMFETEXWAqqoqAMCWLVswbNgwhWMPzlKloaEh/n2/VflgWUvmPr9/76SkJFhZWSkce3Cmxp49eyrsBwYGIjk5GevXr8fAgQOho6ODadOmPXKRFDU1NQiCoFDW2EQfD96vqqoKbm5u2LVrV4O6pqamTd7vUYP0Zs+ejbi4uIfW6SqYqImIOoC5uTksLS2Rn58PX1/fdr9+VlaWwmJEp06dgp6eHqytrWFsbAwtLS0UFhYqdHM3x/HjxzFv3jy8+OKLAO4l0gcHdmlqaoqzyN1namqKkpISCIIg/mPjUd3TAODq6oqEhASYmZm1qLuaXd9ERNRmoaGhWLp0KQwNDeHt7Y2amhqcPXsWf//9t8JiQa1RW1sLPz8/BAUFoaCgACEhIViyZAnU1NSgr6+PwMBA+Pv7Qy6XY+TIkaioqMDx48dhYGCg8Hz8QYMGDUJiYiJ8fHwgk8mwevXqBq15GxsbpKWl4eWXX4aWlhZMTEwwZswYlJeX47333sO0adNw6NAhHDx48JEJ09fXF+vWrcPkyZMRFhaGPn364OrVq0hMTMSKFSvQp0+fRs9ra9d3bm4uqqqqUFJSgtu3b4uJ397eXummsOWobyKiDrJgwQJs3boV27dvh4ODAzw9PfHpp5/C1ta2zdd+9tlnMWjQIIwePRozZszApEmTFCZXCQ8Px+rVqxEVFQU7Ozt4e3sjKSnpkfeOjo5Gr169MHz4cPj4+MDLywuurq4KdcLCwlBQUIABAwaI3dN2dnbYtGkTYmNj4eTkhNOnTyMwMPCRn0NXVxdpaWno27cvpk6dCjs7O/j5+eHOnTsd2ipesGABXFxcsHnzZuTk5IizZF6/fr3D7tlaMuHBhwoqrrKyEoaGhqioqFCprhHqYrh6VqPu3LmDK1euwNbWFtra2mK5Mk94IoV58+bh5s2b2Ldvn9Sh0EM09XsGWpaL2PVNREpP2RMnUUdi1zcREZESY4uaiKiLeXDyE1JtbFETEREpMSZqIiIiJcZETUREpMSYqImIiJQYEzUREZESY6ImIiJSYkzURERESoyJmoioDWQy2UO3f8+/rSpsbGwQExMjdRhtUlhYiIkTJ0JXVxdmZmZYvnw57t69+9BzIiIiMHz4cOjq6sLIyKhzAgUnPCGiruBhc6N3yP2aP996cXGx+HdCQgKCg4ORnZ0tlj1q3WRlIQgC6uvr0aNH56WF2tpaSVaqqq+vx8SJE2FhYYETJ06guLgYc+bMgYaGBiIjI5s8r7a2FtOnT4eHhwe2bdvWafGyRU1E1AYWFhbiZmhoCJlMplC2Z88e2NnZQVtbG4MHD8amTZvEcwsKCiCTyfDll19i1KhR0NHRwZAhQ5CTk4MzZ87A3d0denp6GD9+PMrLy8Xz5s2bhylTpiA0NBSmpqYwMDDAokWLUFtbK9aRy+WIioqCra0tdHR04OTkhL1794rHU1NTIZPJcPDgQbi5uUFLSwvp6enIy8vD5MmTYW5uDj09PQwZMgSHDx8WzxszZgyuXr0Kf39/sdcAANasWQNnZ2eF7yYmJgY2NjYN4o6IiIClpSWeeOIJAEBRURFeeuklGBkZwdjYGJMnT26wBnZ7+vHHH3Hp0iXs3LkTzs7OGD9+PMLDwxEbG6vwHT4oNDQU/v7+cHBw6LDYGsNETUTUQXbt2oXg4GBERETg8uXLiIyMxOrVq7Fjxw6FeiEhIQgKCkJGRgZ69OiBWbNmYcWKFfjggw9w7Ngx5ObmIjg4WOGclJQUXL58Gampqfjiiy+QmJiI0NBQ8XhUVBQ+++wzxMXF4ddff4W/vz9mz56No0ePKlxn5cqVWLt2LS5fvgxHR0dUVVVhwoQJSElJwfnz5+Ht7Q0fHx8UFhYCABITE9GnTx+EhYWhuLhYoUehOVJSUpCdnY3k5GR8//33qKurg5eXF/T19XHs2DEcP34cenp68Pb2fmjS1NPTe+i2aNGiJs89efIkHBwcYG5uLpZ5eXmhsrISv/76a4s+T2dg1zcRUQcJCQnBhg0bMHXqVACAra0tLl26hM2bN2Pu3LlivcDAQHh5eQEAli1bhpkzZyIlJQUjRowAAPj5+TWY31tTUxPx8fHQ1dXFk08+ibCwMCxfvhzh4eGoq6tDZGQkDh8+DA8PDwBA//79kZ6ejs2bN8PT01O8TlhYGJ577jlx39jYGE5OTuJ+eHg4vvnmG+zfvx9LliyBsbEx1NXVoa+vDwsLixZ/Jz179sTWrVvFLu+dO3dCLpdj69atYut8+/btMDIyQmpqKp5//vlGr5OZmfnQ+zxs6ciSkhKFJA1A3C8pKWnuR+k0kifq2NhYrFu3DiUlJXBycsKHH36IoUOHNlk/JiYGH3/8MQoLC2FiYoJp06YhKiqqwVqfRERSunXrFvLy8uDn54eFCxeK5Xfv3oWhoeIzd0dHR/Hv+wnj392r5ubmKCsrUzjHyckJurq64r6HhweqqqpQVFSEqqoqVFdXKyRg4N4zVhcXF4Uyd3d3hf2qqiqsWbMGSUlJKC4uxt27d3H79m2xRd1WDg4OCs+ls7KykJubC319fYV6d+7cQV5eXpPXGThwYLvE0xVImqgTEhIQEBCAuLg4DBs2DDExMfDy8kJ2djbMzMwa1N+9ezdWrlyJ+Ph4DB8+HDk5OZg3bx5kMhmio6Ml+ARERI2rqqoCAGzZsgXDhg1TOKaurq6wr6GhIf59v1X5YJlcLm/xvZOSkmBlZaVwTEtLS2G/Z8+eCvuBgYFITk7G+vXrMXDgQOjo6GDatGkP7YYGADU1NQiCoFBWV1fXoN6D96uqqoKbmxt27drVoK6pqWmT93vUIL3Zs2cjLi6u0WMWFhY4ffq0Qllpaal4TNlImqijo6OxcOFCzJ8/HwAQFxeHpKQkxMfHY+XKlQ3qnzhxAiNGjMCsWbMA3HtFYObMmfj55587NW4iokcxNzeHpaUl8vPz4evr2+7Xz8rKwu3bt6GjowMAOHXqFPT09GBtbQ1jY2NoaWmhsLBQoZu7OY4fP4558+bhxRdfBHAvkT44sEtTUxP19fUKZaampigpKYEgCOI/Nh7VPQ0Arq6uSEhIgJmZ2UO7qx/Ulq5vDw8PREREoKysTGwUJicnw8DAAPb29s2OobNINpistrYW586dw7hx4/4vGDU1jBs3DidPnmz0nOHDh+PcuXPiv4Ty8/Nx4MABTJgwocn71NTUoLKyUmEjIuoMoaGhiIqKwsaNG5GTk4OLFy9i+/bt7dIDWFtbCz8/P1y6dAkHDhxASEgIlixZAjU1Nejr6yMwMBD+/v7YsWMH8vLykJGRgQ8//LDBQLYHDRo0CImJicjMzERWVhZmzZrVoDVvY2ODtLQ0XLt2DX/++SeAe6PBy8vL8d577yEvLw+xsbE4ePDgIz+Hr68vTExMMHnyZBw7dgxXrlxBamoqli5dij/++KPJ8wYOHPjQrbFe2fuef/552Nvb45VXXkFWVhZ++OEHBAUF4fXXXxd7HE6fPo3Bgwfj2rVr4nmFhYXIzMxEYWEh6uvrkZmZiczMTLEHo6NIlqj//PNP1NfXN/pAv6mH+bNmzUJYWBhGjhwJDQ0NDBgwAGPGjMHbb7/d5H2ioqJgaGgobtbW1u36OYiImrJgwQJs3boV27dvh4ODAzw9PfHpp5/C1ta2zdd+9tlnMWjQIIwePRozZszApEmTFCZXCQ8Px+rVqxEVFQU7Ozt4e3sjKSnpkfeOjo5Gr169MHz4cPj4+MDLywuurq4KdcLCwlBQUIABAwaI3dN2dnbYtGkTYmNj4eTkhNOnTyMwMPCRn0NXVxdpaWno27cvpk6dCjs7O/j5+eHOnTstamG3hLq6Or7//nuoq6vDw8MDs2fPxpw5cxAWFibWqa6uRnZ2tkL3fXBwMFxcXBASEoKqqiq4uLjAxcUFZ8+e7ZA475MJDz5U6CTXr1+HlZUVTpw4IY5KBIAVK1bg6NGjjXZnp6am4uWXX8a7776LYcOGITc3F8uWLcPChQuxevXqRu9TU1ODmpoacb+yshLW1taoqKjosB8B0SM9bAKPFky2oWru3LmDK1euwNbWlgNEH2LevHm4efMm9u3bJ3Uo9BAP+z1XVlbC0NCwWblIsmfUJiYmUFdXFx/g31daWtrkw/zVq1fjlVdewYIFCwDcGz1469Yt/L//9//wzjvvQE2tYQeBlpZWg8ETREREXYVkXd+amppwc3NDSkqKWCaXy5GSkqLQwv636urqBsn4/uhJiToGiIiIOpSko74DAgIwd+5cuLu7Y+jQoYiJicGtW7fEUeBz5syBlZUVoqKiAAA+Pj6Ijo6Gi4uL2PW9evVq+Pj4NHjdgYhIVT04+QmpNkkT9YwZM1BeXo7g4GCUlJTA2dkZhw4dEgeYFRYWKrSgg4KCIJPJEBQUhGvXrsHU1BQ+Pj6IiIiQ6iMQERF1KMkGk0mlJQ/wiToMB5M1ioPJSJW012AyLspBRESkxJioiYiIlBgTNRERkRJjoiYiIlJiTNRERERKjImaiKgNZDLZQ7d/z7+tKmxsbBATEyN1GG3S2H+rPXv2SB1WoyR9j5qIqDkcdjh06v0uzr3Y7LrFxcXi3wkJCQgODkZ2drZY9qh1k5WFIAior69Hjx6dlxZqa2uhqanZafd70Pbt2+Ht7S3uGxkZSRbLw7BFTUTUBhYWFuJmaGgImUymULZnzx7Y2dlBW1sbgwcPxqZNm8RzCwoKIJPJ8OWXX2LUqFHQ0dHBkCFDkJOTgzNnzsDd3R16enoYP348ysvLxfPmzZuHKVOmIDQ0FKampjAwMMCiRYtQW1sr1pHL5YiKioKtrS10dHTg5OSEvXv3isdTU1Mhk8lw8OBBuLm5QUtLC+np6cjLy8PkyZNhbm4OPT09DBkyBIcPHxbPGzNmDK5evQp/f3+xJQoAa9asgbOzs8J3ExMTAxsbmwZxR0REwNLSEk888QQAoKioCC+99BKMjIxgbGyMyZMnN1gDuyMYGRkp/LdS1nf3maiJiDrIrl27EBwcjIiICFy+fBmRkZFYvXp1gzWhQ0JCEBQUhIyMDPTo0QOzZs3CihUr8MEHH+DYsWPIzc1FcHCwwjkpKSm4fPkyUlNT8cUXXyAxMRGhoaHi8aioKHz22WeIi4vDr7/+Cn9/f8yePRtHjx5VuM7KlSuxdu1aXL58GY6OjqiqqsKECROQkpKC8+fPw9vbGz4+PigsLAQAJCYmok+fPggLC0NxcbFCj0JzpKSkIDs7G8nJyfj+++9RV1cHLy8v6Ovr49ixYzh+/Dj09PTg7e2t8A+PB+np6T10W7Ro0SNjef3112FiYoKhQ4ciPj5eadeMaFUfx5EjRzB27Nj2joWISKWEhIRgw4YNmDp1KgDA1tYWly5dwubNmzF37lyxXmBgILy8vAAAy5Ytw8yZM5GSkoIRI0YAAPz8/BrM762pqYn4+Hjo6uriySefRFhYGJYvX47w8HDU1dUhMjIShw8fFhc56t+/P9LT07F582Z4enqK1wkLC8Nzzz0n7hsbG8PJyUncDw8PxzfffIP9+/djyZIlMDY2hrq6OvT19Ztc6fBhevbsia1bt4pd3jt37oRcLsfWrVvF1vn27dthZGSE1NRUPP/8841eJzMz86H3edRsX2FhYXjmmWegq6uLH3/8EYsXL0ZVVRWWLl3a4s/U0VqVqL29vdGnTx/Mnz8fc+fOhbW1dXvHRUTUpd26dQt5eXnw8/PDwoULxfK7d+/C0FBxCllHR0fx7/trHTg4OCiUlZWVKZzj5OQEXV1dcd/DwwNVVVUoKipCVVUVqqurFRIwcO+ZsIuLi0KZu7u7wn5VVRXWrFmDpKQkFBcX4+7du7h9+7bYom4rBwcHhefSWVlZyM3Nhb6+vkK9O3fuIC8vr8nrDBw4sE1xrF69WvzbxcUFt27dwrp161QnUV+7dg2ff/45duzYgdDQUDzzzDPw8/PDlClTJB0YQESkLKqqqgAAW7ZswbBhwxSOPbjan4aGhvj3/Vblg2VyubzF905KSoKVlZXCMS0tLYX9nj17KuwHBgYiOTkZ69evx8CBA6Gjo4Np06Y9tBsaANTU1Bp0HdfV1TWo9+D9qqqq4Obmhl27djWoa2pq2uT9HjVIb/bs2YiLi3tonX8bNmwYwsPDUVNT0+A7klqrErWJiQn8/f3h7++PjIwMbN++HYsXL8bixYsxa9Ys+Pn5KXSdEBF1N+bm5rC0tER+fj58fX3b/fpZWVm4ffs2dHR0AACnTp2Cnp4erK2tYWxsDC0tLRQWFip0czfH8ePHMW/ePLz44osA7iXSBwd2aWpqor6+XqHM1NQUJSUlEARB/MfGo7qnAcDV1RUJCQkwMzNr0UJJbe36bux6vXr1UrokDbTD61murq6wsLDAY489hrVr1yI+Ph6bNm2Ch4cH4uLi8OSTT7ZHnEREXU5oaCiWLl0KQ0NDeHt7o6amBmfPnsXff/+NgICANl27trYWfn5+CAoKQkFBAUJCQrBkyRKoqalBX18fgYGB8Pf3h1wux8iRI1FRUYHjx4/DwMBA4fn4gwYNGoTExET4+PhAJpNh9erVDVrzNjY2SEtLw8svvwwtLS2YmJhgzJgxKC8vx3vvvYdp06bh0KFDOHjw4CMTpq+vL9atW4fJkycjLCwMffr0wdWrV5GYmIgVK1agT58+jZ7Xlq7v7777DqWlpXj66aehra2N5ORkREZGIjAwsNXX7EitHvVdV1eHvXv3YsKECejXrx9++OEHfPTRRygtLUVubi769euH6dOnt2esRERdyoIFC7B161Zs374dDg4O8PT0xKeffgpbW9s2X/vZZ5/FoEGDMHr0aMyYMQOTJk1SmFwlPDwcq1evRlRUFOzs7ODt7Y2kpKRH3js6Ohq9evXC8OHD4ePjAy8vL7i6uirUCQsLQ0FBAQYMGCB2T9vZ2WHTpk2IjY2Fk5MTTp8+3azEp6uri7S0NPTt2xdTp06FnZ0d/Pz8cOfOnQ5bilhDQwOxsbHw8PCAs7MzNm/ejOjoaISEhHTI/dqqVetRv/HGG/jiiy8gCAJeeeUVLFiwAE899ZRCnZKSElhaWrbouUpn4HrUpBS4HnWjuB5188ybNw83b97Evn37pA6FHqK91qNuVdf3pUuX8OGHH2Lq1KlN9uebmJjgyJEjrbk8ERER/a9WdX2HhIRg+vTpDZL03bt3kZaWBgDo0aNHiwcxEBERkaJWtajHjh2L4uJimJmZKZRXVFRg7NixDUYDEhFR+3lw8hNSba1qUf97+P2//fXXXw3ekSMiIqLWa1GL+v40eDKZDPPmzVPo+q6vr8eFCxcwfPjw9o2QiIioG2tRor4/7Z0gCNDX1xdftAfuvQD/9NNPK0yVR0TUGsq6OAJRS7TX77hFiXr79u0A7r3sHhgYyG5uImpX96fWrK2tVWgIEHVF1dXVABSng22NVg0mU9aXwomoa+vRowd0dXVRXl4ODQ0NqKlxJV7qegRBQHV1NcrKymBkZNRgbveWanaidnV1RUpKCnr16gUXF5dGB5Pdl5GR0aagiKh7kslk6N27N65cuYKrV69KHQ5RmxgZGbVqKdAHNTtRT548WRw8NmXKlDbf+L7Y2FisW7cOJSUlcHJywocffoihQ4c2Wf/mzZt45513kJiYiBs3bqBfv36IiYnBhAkT2i0mIpKOpqYmBg0a9MjVmoiUmYaGRptb0vc1O1H/u7u7vbq+ExISEBAQgLi4OAwbNgwxMTHw8vJCdnZ2g3e0gXvPrZ577jmYmZlh7969sLKywtWrV2FkZNQu8RCRclBTU+MUokT/q82rZ7VFdHQ0Fi5ciPnz5wMA4uLikJSUhPj4eKxcubJB/fj4eNy4cQMnTpwQH87b2Nh0ZshERESdqtmJulevXg99Lv1vN27ceGSd2tpanDt3DqtWrRLL1NTUMG7cOJw8ebLRc/bv3w8PDw+8/vrr+Pbbb2FqaopZs2bhP//5T5NdDDU1NaipqRH3Kysrm/UZiIiIlEGzE3VMTEy73vjPP/9EfX09zM3NFcrNzc3x22+/NXpOfn4+fvrpJ/j6+uLAgQPIzc3F4sWLUVdX12R3fFRUFEJDQ9s1diIios7S7ET9sIXGO4tcLoeZmRk++eQTqKurw83NDdeuXcO6deuaTNSrVq1SWKC9srIS1tbWnRUyERFRmzQ7UVdWVoprZj6q+7g56zybmJhAXV0dpaWlCuWlpaVNDmfv3bt3g5F0dnZ2KCkpQW1tLTQ1NRuco6Wl1eRSnERERMqu2bMJ9OrVC2VlZQDuvRvWq1evBtv98ubQ1NSEm5sbUlJSxDK5XI6UlBR4eHg0es6IESOQm5sLuVwuluXk5KB3796NJmkiIqKurtkt6p9++gnGxsYAgCNHjrTLzQMCAjB37ly4u7tj6NChiImJwa1bt8RR4HPmzIGVlRWioqIAAK+99ho++ugjLFu2DG+88QZ+//13REZGYunSpe0SDxERkbJpdqL29PRs9O+2mDFjBsrLyxEcHIySkhI4Ozvj0KFD4gCzwsJChSkEra2t8cMPP8Df3x+Ojo6wsrLCsmXL8J///Kdd4iFqTzYrk5o8VsBXhImomWRCK5f3+Pvvv7Ft2zZcvnwZAGBvb4/58+eLrW5lVVlZCUNDQ1RUVDTrWTpRaz08Uc9q+sQ1FR0QDREpk5bkolbNeJ+WlgYbGxts3LgRf//9N/7++29s3LgRtra2SEtLa1XQRERE1FCrZiZ7/fXXMWPGDHz88cfiCOz6+nosXrwYr7/+Oi5evNiuQRIREXVXrWpR5+bm4q233lJ4TUpdXR0BAQHIzc1tt+CIiIi6u1YlaldXV/HZ9L9dvnwZTk5ObQ6KiIiI7ml21/eFCxfEv5cuXYply5YhNzcXTz/9NADg1KlTiI2Nxdq1a9s/SiIiom6q2aO+1dTUIJPJ8KjqMpkM9fX17RJcR+Cob+osHPVNRE1pSS5qdov6ypUrbQ6MiIiIWqbZibpfv34dGQcRERE1olWvZ9136dIlFBYWora2VqF80qRJbQqKiIiI7mlVos7Pz8eLL76IixcvKjy3lslkAKDUz6iJiIi6kla9nrVs2TLY2tqirKwMurq6+PXXX5GWlgZ3d3ekpqa2c4hERETdV6ta1CdPnsRPP/0EExMTqKmpQU1NDSNHjkRUVBSWLl2K8+fPt3ecRERE3VKrWtT19fXQ19cHAJiYmOD69esA7g04y87Obr/oiIiIurlWtaifeuopZGVlwdbWFsOGDcN7770HTU1NfPLJJ+jfv397x0hERNRttSpRBwUF4datWwCAsLAwvPDCCxg1ahQee+wxJCQktGuARERE3VmrErWXl5f498CBA/Hbb7/hxo0b6NWrlzjym4iIiNquTe9RA0BRUREAwNraus3BEBERkaJWDSa7e/cuVq9eDUNDQ9jY2MDGxgaGhoYICgpCXV1de8dIRETUbbWqRf3GG28gMTER7733Hjw8PADce2VrzZo1+Ouvv/Dxxx+3a5BERETdVasS9e7du7Fnzx6MHz9eLHN0dIS1tTVmzpzJRE1ERNROWtX1raWlBRsbmwbltra20NTUbGtMRERE9L9alaiXLFmC8PBw1NTUiGU1NTWIiIjAkiVL2i04IiKi7q7ZXd9Tp05V2D98+DD69OkDJycnAEBWVhZqa2vx7LPPtm+ERERE3VizE7WhoaHC/v/8z/8o7PP1LCIiovbX7ES9ffv2joyDiIiIGtGqZ9T3lZeXIz09Henp6SgvL2/1dWJjY2FjYwNtbW0MGzYMp0+fbtZ5e/bsgUwmw5QpU1p9byIiImXWqkR969YtvPrqq+jduzdGjx6N0aNHw9LSEn5+fqiurm7RtRISEhAQEICQkBBkZGTAyckJXl5eKCsre+h5BQUFCAwMxKhRo1rzEYiIiLqEViXqgIAAHD16FN999x1u3ryJmzdv4ttvv8XRo0fx1ltvteha0dHRWLhwIebPnw97e3vExcVBV1cX8fHxTZ5TX18PX19fhIaGcrUuIiJSaa1K1F9//TW2bduG8ePHw8DAAAYGBpgwYQK2bNmCvXv3Nvs6tbW1OHfuHMaNG/d/AampYdy4cTh58mST54WFhcHMzAx+fn6PvEdNTQ0qKysVNiIioq6iVYm6uroa5ubmDcrNzMxa1PX9559/or6+vsG1zM3NUVJS0ug56enp2LZtG7Zs2dKse0RFRcHQ0FDcODqdiIi6klYlag8PD4SEhODOnTti2e3btxEaGirO/d0R/vnnH7zyyivYsmULTExMmnXOqlWrUFFRIW73V/siIiLqClo113dMTAy8vb0bTHiira2NH374odnXMTExgbq6OkpLSxXKS0tLYWFh0aB+Xl4eCgoK4OPjI5bJ5fJ7H6RHD2RnZ2PAgAEK52hpaUFLS6vZMRERESmTViVqBwcH/P7779i1axd+++03AMDMmTPh6+sLHR2dZl9HU1MTbm5uSElJEV+xksvlSElJaXQq0sGDB+PixYsKZUFBQfjnn3/wwQcfsFubiIhUTosTdV1dHQYPHozvv/8eCxcubHMAAQEBmDt3Ltzd3TF06FDExMTg1q1bmD9/PgBgzpw5sLKyQlRUFLS1tfHUU08pnG9kZAQADcqJiIhUQYsTtYaGhsKz6baaMWMGysvLERwcjJKSEjg7O+PQoUPiALPCwkKoqbVpXhYiIqIuSyYIgtDSkyIjI5GTk4OtW7eiR49W9Z5LprKyEoaGhqioqICBgYHU4ZAKs1mZ1OSxAu1ZTZ+4pqIDoiEiZdKSXNSqLHvmzBmkpKTgxx9/hIODA3r27KlwPDExsTWXJSIioge0KlEbGRk1WD2LiIhUW1O9RAVrJ3ZyJN1LixK1XC7HunXrkJOTg9raWjzzzDNYs2ZNi0Z6ExERUfO1aJRWREQE3n77bejp6cHKygobN27E66+/3lGxERERdXstStSfffYZNm3ahB9++AH79u3Dd999h127domTjhAREVH7alGiLiwsxIQJE8T9cePGQSaT4fr16+0eGBEREbUwUd+9exfa2toKZRoaGqirq2vXoIiIiOieFg0mEwQB8+bNU5g7+86dO1i0aJHCK1p8PYuIiKh9tChRz507t0HZ7Nmz2y0YIiIiUtSiRL19+/aOioOIiIgawUm0iYiIlBgTNRERkRJjoiYiIlJiTNRERERKjImaiIhIiTFRExERKTEmaiIiIiXGRE1ERKTEmKiJiIiUGBM1ERGREmOiJiIiUmJM1EREREqsRYtyEFHHc9jh0OSxi3MvdmIkRKQM2KImIiJSYkzURERESkwpEnVsbCxsbGygra2NYcOG4fTp003W3bJlC0aNGoVevXqhV69eGDdu3EPrExGRdBx2ODS5UfNInqgTEhIQEBCAkJAQZGRkwMnJCV5eXigrK2u0fmpqKmbOnIkjR47g5MmTsLa2xvPPP49r1651cuREREQdT/JEHR0djYULF2L+/Pmwt7dHXFwcdHV1ER8f32j9Xbt2YfHixXB2dsbgwYOxdetWyOVypKSkdHLkREREHU/SRF1bW4tz585h3LhxYpmamhrGjRuHkydPNusa1dXVqKurg7GxcaPHa2pqUFlZqbARERF1FZIm6j///BP19fUwNzdXKDc3N0dJSUmzrvGf//wHlpaWCsn+36KiomBoaChu1tbWbY6biIios0je9d0Wa9euxZ49e/DNN99AW1u70TqrVq1CRUWFuBUVFXVylERERK0n6YQnJiYmUFdXR2lpqUJ5aWkpLCwsHnru+vXrsXbtWhw+fBiOjo5N1tPS0oKWlla7xEtERNTZJG1Ra2pqws3NTWEg2P2BYR4eHk2e99577yE8PByHDh2Cu7t7Z4RKREQkCcmnEA0ICMDcuXPh7u6OoUOHIiYmBrdu3cL8+fMBAHPmzIGVlRWioqIAAP/9738RHByM3bt3w8bGRnyWraenBz09Pck+BxERUUeQPFHPmDED5eXlCA4ORklJCZydnXHo0CFxgFlhYSHU1P6v4f/xxx+jtrYW06ZNU7hOSEgI1qxZ05mhExERdTjJEzUALFmyBEuWLGn0WGpqqsJ+QUFBxwdERESkJLr0qG8iIiJVpxQt6u6ISxkSEVFzsEVNRESkxJioiYiIlBgTNRERkRJjoiYiIlJiTNRERERKjImaiIhIiTFRExERKTEmaiIiIiXGRE1ERKTEmKiJiIiUGBM1ERGREuNc30TUZpy7nlSJsv2e2aImIiJSYkzURERESoxd39RsytYdRETUHbBFTUREpMTYom4jm5VJTR4rWDuxEyMhIiJVxBY1ERGREmOiJiIiUmLs+iaVxgFw1JSu+NvoijFT27FFTUREpMSYqImIiJQYEzUREZESU4pEHRsbCxsbG2hra2PYsGE4ffr0Q+t/9dVXGDx4MLS1teHg4IADBw50UqRERESdS/JEnZCQgICAAISEhCAjIwNOTk7w8vJCWVlZo/VPnDiBmTNnws/PD+fPn8eUKVMwZcoU/PLLL50cORERUceTfNR3dHQ0Fi5ciPnz5wMA4uLikJSUhPj4eKxcubJB/Q8++ADe3t5Yvnw5ACA8PBzJycn46KOPEBcX16mxExERgDWGTR+z7dt5cagoSRN1bW0tzp07h1WrVollampqGDduHE6ePNnoOSdPnkRAQIBCmZeXF/bt29do/ZqaGtTU1Ij7FRUVAIDKyso2Rn+PvKa6yWMPu0f97fpWnSclxtwyD/1tyIQmj0n9PT8V8kOj5b+EejV5jtQxtwZjbrmmftP8Pbfc/esIQtPfnUiQ0LVr1wQAwokTJxTKly9fLgwdOrTRczQ0NITdu3crlMXGxgpmZmaN1g8JCREAcOPGjRs3bkq3FRUVPTJXSt713dFWrVql0AKXy+W4ceMGHnvsMchksna9V2VlJaytrVFUVAQDA4N2vTb9H37PnYPfc+fg99w5lO17FgQB//zzDywtLR9ZV9JEbWJiAnV1dZSWliqUl5aWwsLCotFzLCwsWlRfS0sLWlpaCmVGRkatD7oZDAwMlOKHoOr4PXcOfs+dg99z51Cm79nQ0LBZ9SQd9a2pqQk3NzekpKSIZXK5HCkpKfDw8Gj0HA8PD4X6AJCcnNxkfSIioq5M8q7vgIAAzJ07F+7u7hg6dChiYmJw69YtcRT4nDlzYGVlhaioKADAsmXL4OnpiQ0bNmDixInYs2cPzp49i08++UTKj0FERNQhJE/UM2bMQHl5OYKDg1FSUgJnZ2ccOnQI5ubmAIDCwkKoqf1fw3/48OHYvXs3goKC8Pbbb2PQoEHYt28fnnrqKak+gkhLSwshISENutqpffF77hz8njsHv+fO0ZW/Z5kgNGdsOBEREUlB8pnJiIiIqGlM1EREREqMiZqIiEiJMVETEREpMSZqIiIiJSb561ld2dy5c+Hn54fRo0dLHYrK69+/P86cOYPHHntMofzmzZtwdXVFfn6+RJF1bfv372923UmTJnVgJETUFCbqNqioqMC4cePQr18/zJ8/H3PnzoWVlZXUYamkgoIC1Nc3XNGmpqYG165dkyAi1TBlyhSFfZlMprCaz7/nw2/s+6fW2bFjB0xMTDBx4kQAwIoVK/DJJ5/A3t4eX3zxBfr16ydxhKqpvr4eFy9eRL9+/dCrVy+pw2k2dn23wb59+3Dt2jW89tprSEhIgI2NDcaPH4+9e/eirq5O6vBUwv79+8VW3w8//CDu79+/H9988w3Cw8NhY2MjbZBdmFwuF7cff/wRzs7OOHjwIG7evImbN2/iwIEDcHV1xaFDh6QOVaVERkZCR0cHwL2le2NjY/Hee+/BxMQE/v7+EkenOt58801s27YNwL0k7enpCVdXV1hbWyM1NVXa4FqiGatRUjOdO3dOWLJkiaCtrS2YmJgIb775ppCTkyN1WF2aTCZrctPU1BQef/xx4bvvvpM6TJXw5JNPCseOHWtQnpaWJgwePFiCiFSXjo6OcPXqVUEQBGHFihXCK6+8IgiCIPzyyy+CiYmJlKGpFCsrK+HMmTOCIAjCN998I1haWgrZ2dlCUFCQMHz4cImjaz62qNtJcXExkpOTkZycDHV1dUyYMAEXL16Evb093n//fanD67Lut/b69euH8vJyhRZgTU0NsrOz8cILL0gdpkrIy8trdGU5Q0NDFBQUdHo8qkxPTw9//fUXAODHH3/Ec889BwDQ1tbG7du3pQxNpfz555/iyooHDhzA9OnT8fjjj+PVV1/FxYsXJY6u+Zio26Curg5ff/01XnjhBfTr1w9fffUV3nzzTVy/fh07duzA4cOH8eWXXyIsLEzqULu0uro69O/fHzdu3JA6FJU2ZMgQBAQEKCwjW1paiuXLl2Po0KESRqZ6nnvuOSxYsAALFixATk4OJkyYAAD49ddf+SinHZmbm+PSpUuor6/HoUOHxH8QVVdXQ11dXeLomo+Dydqgd+/ekMvlmDlzJk6fPg1nZ+cGdcaOHdvh61+rOg0NDVy4cEHqMFTetm3bMHXqVPTt2xfW1tYAgKKiInHhG2o/sbGxCAoKQlFREb7++mvxbYZz585h5syZEkenOubPn4+XXnoJvXv3hkwmw7hx4wAAP//8MwYPHixxdM3HRTna4PPPP8f06dOhra0tdSgqz9/fH1paWli7dq3Uoag0QRCQnJyM3377DQBgZ2eHcePGKYz+JupK9u7di6KiIkyfPh19+vQBcG/UvZGRESZPnixxdM3DRN1KdXV10NHRQWZmplIssanq3njjDXz22WcYNGgQ3Nzc0LNnT4Xj0dHREkWmGvh77nzHjh3D5s2bkZ+fj6+++gpWVlb4/PPPYWtri5EjR0odnsq5c+dOl21U8Rl1K2loaKBv3758t7ST/PLLL3B1dYW+vj5ycnJw/vx5ccvMzJQ6vC6Pv+fO9fXXX8PLyws6OjrIyMhATU0NgHtzM0RGRkocneqor69HeHg4rKysoKenJ06MtHr1avG1rS5B0jHnXdzWrVuFCRMmCH/99ZfUoRC1GX/PncfZ2VnYsWOHIAiCoKenJ+Tl5QmCIAgZGRmCubm5lKGplNDQUKF///7Czp07BR0dHfF73rNnj/D0009LHF3zseu7DVxcXJCbm4u6ujr069evQXdsRkaGRJGptj/++AMAxOdN1D74e+48urq6uHTpEmxsbKCvr4+srCz0798f+fn5sLe3x507d6QOUSUMHDgQmzdvxrPPPqvwPf/222/w8PDA33//LXWIzcJR323w4PSL1HHkcjneffddbNiwAVVVVQAAfX19vPXWW3jnnXegpsanOG3F33PnsbCwQG5uboNXsdLT09G/f39pglJB165dw8CBAxuUy+XyLjV7JBN1G4SEhEgdQrfxzjvvYNu2bVi7di1GjBgB4N7/1NasWYM7d+4gIiJC4gi7Pv6eO8/ChQuxbNkyxMfHQyaT4fr16zh58iQCAwOxevVqqcNTGfb29jh27FiDudP37t0LFxcXiaJqBan73ru6v//+W9iyZYuwcuVK8dneuXPnhD/++EPiyFRL7969hW+//bZB+b59+wRLS0sJIiJqPblcLrz77rtCz549xSlxtbW1haCgIKlDUyn79u0TDA0NhbVr1wq6urrCunXrhAULFgiamprCjz/+KHV4zcZn1G1w4cIFjBs3TpxiMTs7G/3790dQUBAKCwvx2WefSR2iytDW1saFCxfw+OOPK5RnZ2fD2dmZ0y62g/r6erz//vv48ssvUVhYiNraWoXjnBmu/dXW1iI3NxdVVVWwt7eHnp6e1CGpnGPHjiEsLAxZWVmoqqqCq6srgoOD8fzzz0sdWrPxwV4bBAQEYN68efj9998V3s+bMGEC0tLSJIxM9Tg5OeGjjz5qUP7RRx/ByclJgohUT2hoKKKjozFjxgxUVFQgICAAU6dOhZqaGtasWSN1eCpJU1MT9vb2GDp0KJN0Bxk1ahSSk5NRVlaG6upqpKend6kkDXDCkzYxNDRERkYGBgwYoDCi8OrVq3jiiSc4crMdHT16FBMnTkTfvn3h4eEB4N7ygEVFRThw4ABGjRolcYRd34ABA7Bx40ZMnDgR+vr6yMzMFMtOnTqF3bt3Sx2iyrh16xbWrl2LlJQUlJWVQS6XKxy//74vtc2CBQswe/ZsjBkzRupQ2oSDydpAS0sLlZWVDcpzcnJgamoqQUSqy9PTEzk5OYiNjRWnt5w6dSoWL14MS0tLiaNTDSUlJXBwcABwb3WniooKAMALL7zAAU7tbMGCBTh69CheeeUVcR5qan/l5eXw9vaGqakpXn75Zfj6+ja6JoPSk/YRedfm5+cnTJkyRaitrRX09PSE/Px84erVq4KLi4uwbNkyqcPr8l588UWhoqJCEARB2LFjh3Dnzh2JI1Jtjz/+uHDq1ClBEARhxIgRQlRUlCAI9yaHMDU1lTI0lWNoaCikp6dLHUa3cOPGDWHz5s2Cp6enoKamJtjb2wsRERHClStXpA6t2dj13QYVFRWYNm0azp49i3/++QeWlpYoKSmBh4cHDhw40GDCCGoZTU1NXL16Fb1794a6ujqKi4thZmYmdVgqa+XKlTAwMMDbb7+NhIQEzJ49GzY2NigsLIS/vz8XRGlHtra2OHDgAOzs7KQOpVv5448/8MUXXyA+Ph6///477t69K3VIzcJE3Q7S09Nx4cIFcUTh/aXUqG0cHR3h6uqKsWPHYv78+di4cSMMDAwarTtnzpxOjk71nTp1CidOnMCgQYPg4+MjdTgqZefOnfj222+xY8cO6OrqSh1Ot1BXV4ekpCTs3LkTSUlJMDY2xrVr16QOq1mYqNugqKhIXLeX2t/x48fx1ltvIS8vDzdu3IC+vn6jz/JkMhlfHSKl5+LiovD7zc3NhSAIsLGxgYaGhkJdTtfafo4cOYLdu3fj66+/hlwux9SpU+Hr64tnnnmmy4wN4GCyNrCxscHIkSMxe/ZsTJs2Db169ZI6JJUyYsQInDp1CgCgpqaGnJwcdn13oL59+2LMmDHw9PTEmDFjMGDAAKlDUimcorXzWVlZ4caNG/D29sYnn3wCHx8faGlpSR1Wi7FF3Qbnz5/H7t27sWfPHnF04ezZs7vsj0HZTJ06FZ9++ikMDAywY8cOvPTSS9DR0ZE6LJW1c+dOpKWlITU1Fbm5ubCysoKnp6eYuAcNGiR1iEQtsmXLFkyfPh1GRkZSh9ImTNTtQBAEpKamNuheiY+Plzq0Lo2DyaRTXFyMo0eP4vvvv0dCQgLkcjnXqm5HZ86cgVwux7BhwxTKf/75Z6irq8Pd3V2iyFRXV151j4m6nWVkZMDPzw8XLlzg/9jaiIPJOt/9mZtSU1Nx5MgRnD9/HnZ2dhgzZgzef/99qcNTGUOHDsWKFSswbdo0hfLExET897//xc8//yxRZKpFVVbdY6JuB3/88Qd2796N3bt345dffoGHhwd8fX2xaNEiqUPr0k6cOIGAgAAOJuskw4cPV0jMnp6eGD16NMdedAA9PT1cuHChwZKWV65cgaOjI/755x+JIlMtq1atwrZt2xAaGtpg1b2FCxd2mVX3OJisDTZv3ozdu3cjPT0ddnZ28PX1xbfffttgSTVqneHDh3MwWSf67bff0LNnTwwePBiDBw+GnZ0dk3QH0dLSQmlpaYNEXVxcjB49+L/l9rJjxw5s3boVkyZNEsscHR1hZWWFxYsXd5lEzRZ1G1hbW2PmzJnw9fXlwhAd7OrVqygsLMTmzZuRn5+Pr776ClZWVvj8889ha2uLkSNHSh1ilycIAi5evIjU1FQcPXoUaWlp0NTUhKenJ8aOHYuFCxdKHaLKmDlzJoqLi/Htt9/C0NAQAHDz5k1MmTIFZmZm+PLLLyWOUDWoyqp7XaODXkkVFhbCx8cH69atw/Dhw8WX5z///HOkp6dLHJ1qOXv2LLy8vKCjo4OMjAzU1NQAuDc7XGRkpMTRqQaZTAZHR0csXboUe/fuxcGDB/Hcc8/hq6++4mOcdrZ+/XoUFRWhX79+GDt2LMaOHQtbW1uUlJRgw4YNUoenMlRl1T22qNvg66+/xiuvvAJfX198/vnnuHTpEvr374+PPvoIBw4cwIEDB6QOUWW4uLjA398fc+bMUVip7Pz58xg/fjxKSkqkDrHLy8jIQGpqKlJTU5Geno5//vkHDg4O4vPqyZMnSx2iSrl16xZ27dqFrKws6OjowNHRETNnzmww+Qm1XlOr7hUWFuLgwYNdZtU9Juo2YPLoPLq6urh06RJsbGwUvuv8/HzY29tzSdF20KNHD7i4uIjvTo8ePVrsliXqqq5du4aPP/4Yly9fBgDY2dl1uVX3OGqhDbKzszF69OgG5YaGhrh582bnB6TCLCwskJubCxsbG4Xy9PT0BgNyqOXq6+uRmJiIUaNGcQBZJ/n9999x5MiRRtejDg4Oligq1fPYY49h0qRJePrpp8Xv+ezZswCgMMhMmTFRtwGTR+dZuHAhli1bhvj4eMhkMly/fh0nT55EYGAg10puB+rq6njppZdw+fJlJupOsGXLFrz22mswMTGBhYWFwmuHMpmMibqdHDp0CHPmzMFff/2FBzuPZTJZ15nrovNW1FQ9kZGRgr29vXDq1ClBX19fOHbsmLBz507B1NRU2Lhxo9ThqRS5XC68++67Qs+ePQWZTCbIZDJBW1tbCAoKkjo0leHm5iYcPnxY6jC6hb59+wpr166VOgyVN3DgQGHx4sVCSUmJ1KG0CZ9Rt4EgCIiMjERUVBSqq6sB3Hs/MjAwEOHh4RJHp5pqa2uRm5uLqqoq2NvbQ09PT+qQVMahQ4ewatUqhIeHw83NrcF66k3NCkctZ2BggMzMTPa8dTADAwOcP3++yy8ww0TdDpg8SBX8ezrFf3fFCoLQtboJuwA/Pz8MGTKEr711sFdffRUjRoyAn5+f1KG0CRM1EQG49yrLw3h6enZSJKovKioK0dHRmDhxIhwcHBq8krV06VKJIlMt1dXVmD59OkxNTbv098xETUTUyWxtbZs8JpPJkJ+f34nRqK5t27Zh0aJF0NbWxmOPPdZg0F5X+Z6ZqIlIdPPmTWzbtk185/TJJ5/Eq6++yvepqUuysLDA0qVLsXLlyi6zUlZjmKiJCIDiNK1Dhw4FcG/d5Nu3b+PHH3+Eq6urxBF2bQEBAQgPD0fPnj0REBDQZD2ZTMZpRNuJsbExzpw5w8FkRKQaRo0ahYEDB2LLli3iCk53797FggULkJ+fj7S0NIkj7NrGjh2Lb775BkZGRhg7dmyT9WQyGX766adOjEx1+fv7w9TUFG+//bbUobQJEzURAQB0dHRw/vx5DB48WKH80qVLcHd3F19BJOoqli5dis8++wxOTk5wdHRsMJgsOjpaoshahjOTERGAe++cFhYWNkjURUVF0NfXlygqota7ePEiXFxcAAC//PKLwrF/DyxTdkzURAQAmDFjBvz8/LB+/XoMHz4cAHD8+HEsX74cM2fOlDg6opY7cuSI1CG0CyZqom7swoULeOqpp6Cmpob169dDJpNhzpw5uHv3LgBAQ0MDr732GtauXStxpETdF59RE3Vj6urqKC4uhpmZGfr3748zZ85AR0cHeXl5AIABAwZAV1dX4iiJuje2qIm6MSMjI1y5cgVmZmYoKCiAXC6Hrq4uHBwcpA6NiP4XEzVRN/Y///M/8PT0RO/evSGTyeDu7g51dfVG63aVWZyIVA0TNVE39sknn2Dq1KnIzc3F0qVLsXDhQo7wJlIyfEZNRACA+fPnY+PGjUzUREqGiZqIiEiJdd1ZyomIiLoBJmoiIiIlxkRNRESkxJioiYiIlBgTNRE9UkFBAWQyGTIzM6UOhajbYaIm6iZkMtlDtzVr1kgdIhE1ghOeEHUTxcXF4t8JCQkIDg5Gdna2WKanpydFWET0CGxRE3UTFhYW4mZoaAiZTCbum5mZITo6Gn369IGWlhacnZ1x6NChJq9VX1+PV199FYMHD0ZhYSEA4Ntvv4Wrqyu0tbXRv39/hIaGiqtwAfda9Fu3bsWLL74IXV1dDBo0CPv37+/wz03U1TFRExE++OADbNiwAevXr8eFCxfg5eWFSZMm4ffff29Qt6amBtOnT0dmZiaOHTuGvn374tixY5gzZw6WLVuGS5cuYfPmzfj0008RERGhcG5oaCheeuklXLhwARMmTICvry9u3LjRWR+TqGsSiKjb2b59u2BoaCjuW1paChEREQp1hgwZIixevFgQBEG4cuWKAEA4duyY8OyzzwojR44Ubt68KdZ99tlnhcjISIXzP//8c6F3797iPgAhKChI3K+qqhIACAcPHmzPj0akcviMmqibq6ysxPXr1zFixAiF8hEjRiArK0uhbObMmejTpw9++ukn6OjoiOVZWVk4fvy4Qgu6vr4ed+7cQXV1tbimtaOjo3i8Z8+eMDAwQFlZWUd8LCKVwURNRM02YcIE7Ny5EydPnsQzzzwjlldVVSE0NBRTp05tcI62trb4t4aGhsIxmUwGuVzecQETqQAmaqJuzsDAAJaWljh+/Dg8PT3F8uPHj2Po0KEKdV977TU89dRTmDRpEpKSksT6rq6uyM7OxsCBAzs1dqLugImaiLB8+XKEhIRgwIABcHZ2xvbt25GZmYldu3Y1qPvGG2+gvr4eL7zwAg4ePIiRI0ciODgYL7zwAvr27Ytp06ZBTU0NWVlZ+OWXX/Duu+9K8ImIVAcTNRFh6dKlqKiowFtvvYWysjLY29tj//79GDRoUKP133zzTcjlckyYMAGHDh2Cl5cXvv/+e4SFheG///0vNDQ0MHjwYCxYsKCTPwmR6uF61EREREqM71ETEREpMSZqIiIiJcZETUREpMSYqImIiJQYEzUREZESY6ImIiJSYkzURERESoyJmoiISIkxURMRESkxJmoiIiIlxkRNRESkxJioiYiIlNj/B0kqKuhJgek7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperature =[1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperature]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperature):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f\"Temperature = {T}\")\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Token')\n",
    "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cfd05d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "top_logits = torch.topk(next_token_logits, k=3).values\n",
    "new_logits = torch.where(next_token_logits <top_logits[-1],torch.tensor(-float(\"inf\")),next_token_logits)\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9533c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d5baeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits = torch.topk(logits, k=top_k).values\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(-float(\"inf\")).to(logits.device), logits)\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba014dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "43b363a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bf7c32df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff89be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),   \n",
    "},\"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c789e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdadab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f590081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
